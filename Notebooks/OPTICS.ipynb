{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "COMP-6651 - Algorithm Design Techniques\n",
        "\n",
        "Project - Clustering Algorithms Analysis\n",
        "\n",
        "OPTICS Experimentation\n",
        "\n",
        "Author - Nitheesh Kumar Kambala - 40299620\n"
      ],
      "metadata": {
        "id": "MKxpNrGRJL8f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wupD654OJHdQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd065df9-ad9a-438c-b55a-d50bfc09a7a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/himanshunakrani/iris-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 0.98k/0.98k [00:00<00:00, 1.15MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/katerynameleshenko/ai-index?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.38k/2.38k [00:00<00:00, 1.00MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/shreyasur965/recent-earthquakes?dataset_version_number=3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 214k/214k [00:00<00:00, 35.7MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import OPTICS\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
        "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score, adjusted_rand_score, mutual_info_score, accuracy_score\n",
        "from scipy.spatial.distance import cdist, pdist\n",
        "from heapq import heappush, heappop\n",
        "import os\n",
        "import kagglehub\n",
        "\n",
        "path_iris = kagglehub.dataset_download(\"himanshunakrani/iris-dataset\")\n",
        "f_path_iris = os.path.join(path_iris, 'iris.csv')\n",
        "iris_df = pd.read_csv(f_path_iris)\n",
        "iris_data_target = iris_df['species']\n",
        "iris_data_features = iris_df.drop(columns=['species']).values\n",
        "\n",
        "# Preprocessing for AI Global Index Dataset\n",
        "def preprocess_ai_index(data):\n",
        "    # Separate numerical and categorical columns\n",
        "    numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
        "    categorical_cols = data.select_dtypes(exclude=[np.number]).columns\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    num_scaled = scaler.fit_transform(data[numeric_cols]) if len(numeric_cols) > 0 else np.array([])\n",
        "\n",
        "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "    cat_encoded = encoder.fit_transform(data[categorical_cols]) if len(categorical_cols) > 0 else np.array([])\n",
        "\n",
        "    if num_scaled.size and cat_encoded.size:\n",
        "        return np.hstack((num_scaled, cat_encoded))\n",
        "    elif num_scaled.size:\n",
        "        return num_scaled\n",
        "    else:\n",
        "        return cat_encoded\n",
        "\n",
        "path_ai_index = kagglehub.dataset_download(\"katerynameleshenko/ai-index\")\n",
        "f_path_ai_index = os.path.join(path_ai_index, 'AI_index_db.csv')\n",
        "ai_df = pd.read_csv(f_path_ai_index).dropna()\n",
        "ai_data_target = ai_df['Cluster']\n",
        "ai_data_features = ai_df.drop(columns=['Cluster'])\n",
        "ai_data_features = preprocess_ai_index(ai_data_features)\n",
        "\n",
        "# Load Global Earthquake Dataset\n",
        "path_earthquakes= kagglehub.dataset_download(\"shreyasur965/recent-earthquakes\")\n",
        "f_path_earthquakes = os.path.join(path_earthquakes, 'earthquakes.csv')\n",
        "earthquake_df = pd.read_csv(f_path_earthquakes)\n",
        "earthquake_df = earthquake_df[['magnitude', 'felt', 'cdi','mmi','tsunami','sig','depth', 'latitude', 'longitude', 'alert']].dropna()\n",
        "earthquake_data_target = earthquake_df['alert']\n",
        "earthquake_data_features = earthquake_df.drop(columns=['alert'])\n",
        "earthquake_data_features = StandardScaler().fit_transform(earthquake_data_features)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BASE_OPTICS:\n",
        "    def __init__(self, min_pts):\n",
        "        self.min_pts = min_pts\n",
        "\n",
        "    def fit(self, data):\n",
        "        self.data = data\n",
        "        n = len(data)\n",
        "        self.reachability = np.full(n, np.inf)\n",
        "        self.ordered_list = []\n",
        "        self.processed = np.zeros(n, dtype=bool)\n",
        "\n",
        "        for i in range(n):\n",
        "            if not self.processed[i]:\n",
        "                neighbors = self.region_query(i)\n",
        "                self.processed[i] = True\n",
        "                self.ordered_list.append(i)\n",
        "\n",
        "                if len(neighbors) >= self.min_pts:\n",
        "                    self.expand_cluster_order(i, neighbors)\n",
        "\n",
        "        return self.ordered_list, self.reachability\n",
        "\n",
        "    def region_query(self, point_idx):\n",
        "        dists = cdist([self.data[point_idx]], self.data)[0]\n",
        "        return np.where(dists <= self.eps(point_idx))[0]\n",
        "\n",
        "    def eps(self, point_idx):\n",
        "        dists = cdist([self.data[point_idx]], self.data)[0]\n",
        "        sorted_dists = np.sort(dists)\n",
        "        return sorted_dists[self.min_pts] if len(sorted_dists) > self.min_pts else np.inf\n",
        "\n",
        "    def expand_cluster_order(self, point_idx, neighbors):\n",
        "        priority_queue = []\n",
        "\n",
        "        for neighbor in neighbors:\n",
        "            if not self.processed[neighbor]:\n",
        "                self.reachability[neighbor] = max(self.eps(point_idx), cdist([self.data[point_idx]], [self.data[neighbor]])[0][0])\n",
        "                heappush(priority_queue, (self.reachability[neighbor], neighbor))\n",
        "\n",
        "        while priority_queue:\n",
        "            _, current = heappop(priority_queue)\n",
        "            if not self.processed[current]:\n",
        "                self.processed[current] = True\n",
        "                self.ordered_list.append(current)\n",
        "                new_neighbors = self.region_query(current)\n",
        "\n",
        "                if len(new_neighbors) >= self.min_pts:\n",
        "                    for neighbor in new_neighbors:\n",
        "                        if not self.processed[neighbor]:\n",
        "                            new_reach = max(self.eps(current), cdist([self.data[current]], [self.data[neighbor]])[0][0])\n",
        "                            if new_reach < self.reachability[neighbor]:\n",
        "                                self.reachability[neighbor] = new_reach\n",
        "                                heappush(priority_queue, (new_reach, neighbor))"
      ],
      "metadata": {
        "id": "u5Lw1bc8Kq0d"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sklearn_optics(data, min_pts):\n",
        "    sklearn_optics = OPTICS(min_samples=min_pts, metric='euclidean')\n",
        "    sklearn_optics.fit(data)\n",
        "    return sklearn_optics.labels_, sklearn_optics.reachability_"
      ],
      "metadata": {
        "id": "Pq4lf5BIK_84"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def map_clusters_to_labels(cluster_labels, actual_labels):\n",
        "    cluster_mapping = {}\n",
        "    predicted_alerts = np.full_like(cluster_labels, fill_value=\"None\", dtype=object)\n",
        "    unique_clusters = np.unique(cluster_labels)\n",
        "    for cluster in unique_clusters:\n",
        "        if cluster == -1:\n",
        "            continue\n",
        "        cluster_indices = np.where(cluster_labels == cluster)[0]\n",
        "        cluster_alerts = actual_labels[cluster_indices]\n",
        "        most_common_alert = Counter(cluster_alerts).most_common(1)[0][0]\n",
        "        cluster_mapping[cluster] = most_common_alert\n",
        "        predicted_alerts[cluster_indices] = most_common_alert\n",
        "    return cluster_mapping, predicted_alerts\n",
        "\n",
        "def compute_clusters_mean_diameter(X, labels):\n",
        "    diameters = []\n",
        "    for cluster in np.unique(labels):\n",
        "        if cluster == -1:\n",
        "            continue\n",
        "        points = X[labels == cluster]\n",
        "        if len(points) < 2:\n",
        "            diameters.append(0)\n",
        "            continue\n",
        "        dists = pdist(points)\n",
        "        diameters.append(np.max(dists))\n",
        "    return np.mean(diameters)\n",
        "\n",
        "def compute_clusters_mean_splits(X, labels):\n",
        "    splits = []\n",
        "    for cluster in np.unique(labels):\n",
        "        if cluster == -1:\n",
        "            continue\n",
        "        in_cluster = X[labels == cluster]\n",
        "        out_cluster = X[labels != cluster]\n",
        "        if len(out_cluster) == 0:\n",
        "            splits.append(0)\n",
        "            continue\n",
        "        dists = cdist(in_cluster, out_cluster)\n",
        "        splits.append(np.min(dists))\n",
        "    return np.mean(splits)\n",
        "\n",
        "def get_labels(data, ordered_list, reachability, eps_threshold):\n",
        "    labels = np.full(len(data), -1)\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        if reachability[i] <= eps_threshold:\n",
        "            labels[i] = ordered_list[i]\n",
        "\n",
        "    return labels\n",
        "\n",
        "def compute_metrics(data, labels, target, predicted):\n",
        "    if len(set(labels)) > 1:\n",
        "        silhouette = silhouette_score(data, labels)\n",
        "        davies_bouldin = davies_bouldin_score(data, labels)\n",
        "        calinski_harabasz = calinski_harabasz_score(data, labels)\n",
        "        ari = adjusted_rand_score(target, predicted)\n",
        "        mi = mutual_info_score(target, predicted)\n",
        "        accuracy = accuracy_score(target, predicted)\n",
        "        mean_diameter = compute_clusters_mean_diameter(data, predicted)\n",
        "        mean_splits = compute_clusters_mean_splits(data, labels)\n",
        "    else:\n",
        "        silhouette, davies_bouldin, calinski_harabasz,ari, mi, accuracy, mean_diameter, mean_split = None, None, None, None, None, None, None, None\n",
        "\n",
        "    return {\n",
        "        'Silhouette Score': silhouette,\n",
        "        'Davies-Bouldin Index': davies_bouldin,\n",
        "        'Calinski-Harabasz Index': calinski_harabasz,\n",
        "        'ARI': ari,\n",
        "        'MI': mi,\n",
        "        'Mean Diameter': mean_diameter,\n",
        "        'Mean Splits': mean_splits,\n",
        "        'Accuracy': accuracy\n",
        "    }"
      ],
      "metadata": {
        "id": "37sd_aFkMHQX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optics_experimentation(dataset_name, features, target, min_pts, eps_threshold):\n",
        "    print(f\"\\nProcessing {dataset_name} Dataset\")\n",
        "\n",
        "    # BASE OPTICS\n",
        "    base_ordered_list, base_reachability = BASE_OPTICS(min_pts).fit(features)\n",
        "    base_labels = get_labels(features, base_ordered_list, base_reachability, eps_threshold)\n",
        "    base_cluster_mapping, base_predicted = map_clusters_to_labels(base_labels, target.values)\n",
        "    base_metrics = compute_metrics(features, base_labels, target, base_predicted)\n",
        "    print(\"BASE OPTICS Metrics:\")\n",
        "    for k, v in base_metrics.items():\n",
        "        print(f\"  {k}: {v:.4f}\")\n",
        "\n",
        "    # Scikit-learn OPTICS\n",
        "    sklearn_ordered_list, sklearn_reachability = sklearn_optics(features, min_pts)\n",
        "    sklearn_labels = get_labels(features, sklearn_ordered_list, sklearn_reachability, eps_threshold)\n",
        "    sklearn_cluster_mapping, sklearn_predicted = map_clusters_to_labels(sklearn_labels, target.values)\n",
        "    sklearn_metrics = compute_metrics(features, sklearn_labels, target, sklearn_predicted)\n",
        "    print(\"Scikit-learn OPTICS Metrics:\")\n",
        "    for k, v in sklearn_metrics.items():\n",
        "        print(f\"  {k}: {v:.4f}\")\n",
        "    return base_labels, sklearn_labels"
      ],
      "metadata": {
        "id": "_mD_QCSsMJDD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris_base_labels, iris_sklearn_labels = optics_experimentation('Iris', iris_data_features, iris_data_target, 5, 1)"
      ],
      "metadata": {
        "id": "Avs-zf5nyttt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "492f6e00-ef4a-429f-95b9-5467c963e146"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing Iris Dataset\n",
            "BASE OPTICS Metrics:\n",
            "  Silhouette Score: -0.0790\n",
            "  Davies-Bouldin Index: 2.1060\n",
            "  Calinski-Harabasz Index: 0.6453\n",
            "  ARI: 0.8550\n",
            "  MI: 1.0020\n",
            "  Mean Diameter: 3.6180\n",
            "  Mean Splits: 0.2262\n",
            "  Accuracy: 0.9067\n",
            "Scikit-learn OPTICS Metrics:\n",
            "  Silhouette Score: -0.2268\n",
            "  Davies-Bouldin Index: 2.7337\n",
            "  Calinski-Harabasz Index: 15.4383\n",
            "  ARI: 0.1526\n",
            "  MI: 0.4013\n",
            "  Mean Diameter: 2.8074\n",
            "  Mean Splits: 0.2323\n",
            "  Accuracy: 0.3867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ai_global_base_labels, ai_global_sklearn_labels = optics_experimentation('AI Global Index', ai_data_features, ai_data_target, 5, 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5V_veh54fmv",
        "outputId": "2c033a95-5056-4eb6-ca15-1c05c9d39c0d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing AI Global Index Dataset\n",
            "BASE OPTICS Metrics:\n",
            "  Silhouette Score: -0.0705\n",
            "  Davies-Bouldin Index: 1.0476\n",
            "  Calinski-Harabasz Index: 0.7102\n",
            "  ARI: 0.1166\n",
            "  MI: 0.3779\n",
            "  Mean Diameter: 2.2589\n",
            "  Mean Splits: 1.4306\n",
            "  Accuracy: 0.3710\n",
            "Scikit-learn OPTICS Metrics:\n",
            "  Silhouette Score: 0.0671\n",
            "  Davies-Bouldin Index: 1.8726\n",
            "  Calinski-Harabasz Index: 5.9671\n",
            "  ARI: 0.0538\n",
            "  MI: 0.1512\n",
            "  Mean Diameter: 2.5514\n",
            "  Mean Splits: 1.4298\n",
            "  Accuracy: 0.3065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "earthquake_base_labels, earthquake_sklearn_labels = optics_experimentation('Earthquake', earthquake_data_features, earthquake_data_target, 5, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a99YokiK4kzw",
        "outputId": "33eb2a0c-d920-4e38-f364-bcc23ad0cfc3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing Earthquake Dataset\n",
            "BASE OPTICS Metrics:\n",
            "  Silhouette Score: -0.2135\n",
            "  Davies-Bouldin Index: 1.5069\n",
            "  Calinski-Harabasz Index: 0.3043\n",
            "  ARI: 0.2032\n",
            "  MI: 0.1543\n",
            "  Mean Diameter: 9.4189\n",
            "  Mean Splits: 0.0666\n",
            "  Accuracy: 0.6950\n",
            "Scikit-learn OPTICS Metrics:\n",
            "  Silhouette Score: -0.1555\n",
            "  Davies-Bouldin Index: 1.4743\n",
            "  Calinski-Harabasz Index: 6.2817\n",
            "  ARI: 0.0532\n",
            "  MI: 0.1103\n",
            "  Mean Diameter: 9.9306\n",
            "  Mean Splits: 0.3502\n",
            "  Accuracy: 0.4110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Predicting alert-level based on clusters and analyzing how good the prediction is."
      ],
      "metadata": {
        "id": "U8ILcunW0SAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "earthquake_base_labels, earthquake_sklearn_labels = optics_experimentation('Earthquake', earthquake_data_features, earthquake_data_target, 5, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sl7in5-F1Pjv",
        "outputId": "8dfe4c2d-6359-4740-a988-b883fd1feb97"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing Earthquake Dataset\n",
            "BASE OPTICS Metrics:\n",
            "  Silhouette Score: -0.2135\n",
            "  Davies-Bouldin Index: 1.5069\n",
            "  Calinski-Harabasz Index: 0.3043\n",
            "  ARI: 0.2032\n",
            "  MI: 0.1543\n",
            "  Mean Diameter: 9.4189\n",
            "  Mean Splits: 0.0666\n",
            "  Accuracy: 0.6950\n",
            "Scikit-learn OPTICS Metrics:\n",
            "  Silhouette Score: -0.1555\n",
            "  Davies-Bouldin Index: 1.4743\n",
            "  Calinski-Harabasz Index: 6.2817\n",
            "  ARI: 0.0532\n",
            "  MI: 0.1103\n",
            "  Mean Diameter: 9.9306\n",
            "  Mean Splits: 0.3502\n",
            "  Accuracy: 0.4110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Reducing the number of attributes to 5 using Mutual Information Scores between feature and alert level."
      ],
      "metadata": {
        "id": "tcB3pg8h1QUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import mutual_info_classif\n",
        "\n",
        "X = earthquake_data_features\n",
        "y = earthquake_data_target\n",
        "\n",
        "# Compute MI scores\n",
        "mi_scores = mutual_info_classif(X, y)\n",
        "\n",
        "# Select top 5 features\n",
        "top_5_features = np.array(np.arange(X.shape[1]))[mi_scores.argsort()[-5:]]\n",
        "\n",
        "print(\"Top 5 features most predictive of 'alert':\", earthquake_df.columns[top_5_features])\n",
        "\n",
        "X_selected = X[:, top_5_features]\n",
        "\n",
        "earthquake_data_top_5 = X_selected"
      ],
      "metadata": {
        "id": "UJkrQhzr1TPx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d8b77d5-7854-4666-b837-486ccda97e9f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 features most predictive of 'alert': Index(['magnitude', 'latitude', 'longitude', 'mmi', 'sig'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 Running clustering experimentation for both base and library implementation for top-5 attribute of earthquake data"
      ],
      "metadata": {
        "id": "Y48t_WkV1XjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_labels, sklearn_labels = optics_experimentation('Earthquake', earthquake_data_top_5, earthquake_data_target, 5, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A446pE9B1VfT",
        "outputId": "ba971256-23ba-4a5f-9e80-ea6c461a8b31"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing Earthquake Dataset\n",
            "BASE OPTICS Metrics:\n",
            "  Silhouette Score: -0.1604\n",
            "  Davies-Bouldin Index: 1.4623\n",
            "  Calinski-Harabasz Index: 0.5502\n",
            "  ARI: 0.3622\n",
            "  MI: 0.2020\n",
            "  Mean Diameter: 4.0045\n",
            "  Mean Splits: 0.0416\n",
            "  Accuracy: 0.8102\n",
            "Scikit-learn OPTICS Metrics:\n",
            "  Silhouette Score: -0.0097\n",
            "  Davies-Bouldin Index: 1.3400\n",
            "  Calinski-Harabasz Index: 12.7160\n",
            "  ARI: 0.1201\n",
            "  MI: 0.1706\n",
            "  Mean Diameter: 3.7755\n",
            "  Mean Splits: 0.2677\n",
            "  Accuracy: 0.5105\n"
          ]
        }
      ]
    }
  ]
}